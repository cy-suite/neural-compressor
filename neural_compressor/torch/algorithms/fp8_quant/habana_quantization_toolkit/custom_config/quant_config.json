{
    "mode": "QUANTIZE",
    "scale_method": "without_scale",
    "fp8_config": "E4M3",
    "allowlist": {
        "types": [
            "torch.nn.Linear",
            "torch.nn.Conv2d"
        ]
    },
    "dump_stats_path": "./run_outputs/fp8/stats"
}