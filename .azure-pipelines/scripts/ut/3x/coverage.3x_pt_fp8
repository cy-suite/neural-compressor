[run]
branch = True

[report]
include =
 */neural_compressor/torch/algorithms/habana_fp8/*
 */neural_compressor/torch/amp/*
exclude_lines =
 pragma: no cover
 raise NotImplementedError
 raise TypeError
 if self.device == "gpu":
 if device == "gpu":
 except ImportError:
 except Exception as e: